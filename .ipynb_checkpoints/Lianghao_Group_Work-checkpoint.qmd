---
bibliography: bio.bib
csl: harvard-cite-them-right.csl
title: Group Name's Group Project
execute:
  echo: false
  freeze: true
format:
  html:
    code-copy: true
    code-link: true
    toc: true
    toc-title: On this page
    toc-depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
  pdf:
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}
    papersize: a4
    geometry:
      - top=25mm
      - left=40mm
      - right=30mm
      - bottom=25mm
      - heightrounded
    toc: false
    number-sections: false
    colorlinks: true
    highlight-style: github
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.16.4
  kernelspec:
    display_name: Python (base)
    language: python
    name: base
---

```{python}
#| echo: false
import os
import numpy as np
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
```

```{python}
def check_cache(f):
    @wraps(f)
    def wrapper(src, dst, min_size=100):
        url = urlparse(src) # We assume that this is some kind of valid URL 
        fn  = os.path.split(url.path)[-1] # Extract the filename
        dsn = os.path.join(dst,fn) # Destination filename
        if os.path.isfile(dsn) and os.path.getsize(dsn) > min_size:
            print(f"+ {dsn} found locally!")
            return(dsn)
        else:
            print(f"+ {dsn} not found, downloading!")
            return(f(src, dsn))
    return wrapper

@check_cache
def cache_data(src:str, dst:str) -> str:
    """Downloads a remote file.
    
    The function sits between the 'read' step of a pandas or geopandas
    data frame and downloading the file from a remote location. The idea
    is that it will save it locally so that you don't need to remember to
    do so yourself. Subsequent re-reads of the file will return instantly
    rather than downloading the entire file for a second or n-th itme.
    
    Parameters
    ----------
    src : str
        The remote *source* for the file, any valid URL should work.
    dst : str
        The *destination* location to save the downloaded file.
        
    Returns
    -------
    str
        A string representing the local location of the file.
    """

    # Convert the path back into a list (without)
    # the filename -- we need to check that directories
    # exist first.
    path = os.path.split(dst)[0]
    print(f"Path: {path}")
      
    # Create any missing directories in dest(ination) path
    # -- os.path.join is the reverse of split (as you saw above)
    # but it doesn't work with lists... so I had to google how
    # to use the 'splat' operator! os.makedirs creates missing
    # directories in a path automatically.
    if path != '':
        os.makedirs(path, exist_ok=True)
        
    # Download and write the file
    with open(dst, "wb") as file:
        response = get(src)
        file.write(response.content)
        
    print(' + Done downloading...')

    return dst
```

```{python}
#| echo: false
host = "https://orca.casa.ucl.ac.uk"
path = "~jreades/data"
file = "20240614-London-listings.parquet"

if os.path.exists(file):
    df = pd.read_parquet(file)
else:
    df = pd.read_parquet(f"{host}/{path}/{file}")
    df.to_parquet(file)
df.shape
```


## Declaration of Authorship {.unnumbered .unlisted}

We, [insert your group's names], pledge our honour that the work presented in this assessment is our own. Where information has been derived from other sources, we confirm that this has been indicated in the work. Where a Large Language Model such as ChatGPT has been used we confirm that we have made its contribution to the final submission clear.

Date:

Student Numbers: 

## Brief Group Reflection

| What Went Well | What Was Challenging |
| -------------- | -------------------- |
| A              | B                    |
| C              | D                    |

## Priorities for Feedback

Are there any areas on which you would appreciate more detailed feedback if we're able to offer it?

{{< pagebreak >}}

# Response to Questions

See the raw file for examples of how to hide computational output as there is code hidden here.

## 1. Who collected the InsideAirbnb data?

::: {.duedate}

( 2 points; Answer due Week 7 )

As a mission driven, grassroots project, Inside Airbnb relies on the generous support of collaborators who choose to contribute to the project.

1. Murray Cox. Murray is a community artist and activist who uses data, media and technology for social change. He is the founder and current chief data activist of Inside Airbnb.
2. John Morris. John, an artist and designer, was a founding collaborator who designed and re-designed the website, and is the creative producer of the project's major reports.
3. Taylor Higgins. Taylor is working on her masters in Florence, Italy at the Scuola di Economia e Statistiche (School of Economics and Statistics) at the Università degli Studi di Firenze with a focus on designing sustainable tourism systems. Taylor is working to build and organise the data and activist communities of Inside Airbnb.



:::

An inline citation example: As discussed on @insideairbnb, there are many...

A parenthetical citation example: There are many ways to research Airbnb [see, for example, @insideairbnb]... 


## 2. Why did they collect the InsideAirbnb data?

::: {.duedate}

( 4 points; Answer due Week 7 )

Inside Airbnb is a mission driven project that provides data and advocacy about Airbnb's impact on residential communities.

"We work towards a vision where communities are empowered with data and information to understand, decide and control the role of renting residential homes to tourists."




:::

```{python}
#| output: asis
print(
    f"One of way to embed output in the text looks like this: after cleaning, we were left with {df.shape[0]:,} rows of data."
)
```

This way is also supposed to work (`{python} f"{df.shape[0]:,}" `) but I've found it less reliable.

```{python}
ax = df.host_listings_count.plot.hist(bins=50)
ax.set_xlim([0, 500]);
```

## 3. How did they collect it?

::: {.duedate}

( 5 points; Answer due Week 8 )

:::


## 3. How did they collect it?

::: {.duedate}

( 5 points; Answer due Week 8 )

:::

## 4. How does the method of collection (Q3) impact the completeness and/or accuracy of the InsideAirbnb data? How well does it represent the process it seeks to study, and what wider issues does this raise?

::: {.duedate}

( 11 points; Answer due Week 9 )

:::

## 5. What ethical considerations does the use of the InsideAirbnb data raise? 

::: {.duedate}

( 18 points; Answer due {{< var assess.group-date >}} )

:::

## 6. With reference to the InsideAirbnb data (*i.e.* using numbers, figures, maps, and descriptive statistics), what does an analysis of Hosts and the types of properties that they list suggest about the nature of Airbnb lettings in London? 

::: {.duedate}

( 15 points; Answer due {{< var assess.group-date >}} )

:::

```{python}
gdf = gpd.GeoDataFrame(df, crs='EPSG:4326', geometry=gpd.points_from_xy(df.longitude, df.latitude)).to_crs(27700)

london = gpd.read_file('data/London/London_Borough_Excluding_MHW.shp').to_crs(gdf.crs) # British National Grid
green = gpd.read_file('data/Greenspace.gpkg').to_crs(27700)
water = gpd.read_file('data/Water.gpkg').to_crs(27700)

#london.plot()
# london
```

```{python}
london
```

### 6.1 Location of Airbnb listings in London

```{python}
import matplotlib.patches as mpatches
import matplotlib.lines as mlines

# 创建并列子图
fig, axes = plt.subplots(1, 2, figsize=(16, 12))  # 1行2列

# --- 第一个子图  ---
london.plot(ax=axes[0], color='whitesmoke', edgecolor='black')
gdf.plot(ax=axes[0], color='black', marker='o', markersize=1)
axes[0].set_title('The distribution of Airbnb houses in London',
                  fontdict={'fontsize': 15, 'fontweight': '3'})

#取消边框
axes[0].spines['top'].set_visible(False)
axes[0].spines['right'].set_visible(False)
axes[0].spines['bottom'].set_visible(False)
axes[0].spines['left'].set_visible(False)

axes[0].set_xlabel('Longitude')
axes[0].set_ylabel('Latitude')

# --- 第二个子图 ---
# Plot all three GeoPackages to the second axes

water.plot(facecolor='xkcd:sky blue', zorder=1, ax=axes[1], label='Water bodies')
green.plot(facecolor=(0.5, 0.8, 0, 0.6), zorder=2, ax=axes[1], label='Green spaces')
london.plot(edgecolor='black', facecolor='none', 
                  linewidth=0.2, zorder=3, ax=axes[1], label='Ward boundaries')
gdf.to_crs(green.crs).plot(column='price', cmap='viridis', alpha=0.25, 
                           markersize=1, label='Listings by price', zorder=4, ax=axes[1])

#取消边框
axes[1].spines['top'].set_visible(False)
axes[1].spines['right'].set_visible(False)
axes[1].spines['bottom'].set_visible(False)
axes[1].spines['left'].set_visible(False)

# 设置范围
axes[1].set_xlim(501000, 563000)
axes[1].set_ylim(155000, 202000)
axes[1].set_title('Map with more information', 
                  fontdict={'fontsize': 15, 'fontweight': '3'})

# 手动创建图例条目
legend_handles = [
    mpatches.Patch(color='xkcd:sky blue', label='Water bodies'),
    mpatches.Patch(color=(0.5, 0.8, 0, 0.6), label='Green spaces'),
    mlines.Line2D([], [], color='purple', marker='o', linestyle='None', markersize=1, alpha=0.25, label='Listings'),
    mlines.Line2D([], [], color=(0.8, 0, 0, 0.5), linewidth=1, label='Borough boundaries')
]

# 添加自定义图例
axes[1].legend(handles=legend_handles, title="Legend", loc='lower left', fontsize=10)


# 调整布局并显示
plt.tight_layout()
plt.show()
```

* There is a apparent trend that airbnb listings are concentrated in the city center, and the number decreases as it moves into the suburbs. 
* Although the listings are mainly concentrated in the city centre, it is worth noting that the listings in the central area have several obvious blank areas, which we can see from the chart on the right that this is due to the distribution of green Spaces there.

## 可要可不要

```{python}
# 空间连接 (Spatial Join) 
# 将 gdf 中的点与 london 中的区域连接
joined = gpd.sjoin(gdf, london, how='left', predicate='within')  # 表示 gdf 中的点应位于 london 区域内

# 统计每个区域中的点数量
ward_counts = joined.groupby('GSS_CODE').size()  

# 将统计结果添加到 London GeoDataFrame
london['point_count'] = london['GSS_CODE'].map(ward_counts)
london['point_density'] = london['point_count'] / london['HECTARES']

# 绘制结果
fig, ax = plt.subplots(figsize=(10, 6))
london.plot(ax=ax, column='point_density', cmap='OrRd', legend=True,
            legend_kwds={'label': "Point Density per Ward"},
            edgecolor='black', linewidth=0.1)  # 设置边界线颜色和宽度

# 更新标题以反映点密度
ax.set_title('Density of Points in London Boroughs (per hectare)', fontsize=16)
plt.show()
```

`This confirms the previously observed phenomenon: while listings are primarily concentrated in the city center, there are still some areas within the center with relatively few listings.`

### 6.2 Analysis of Hosts

```{python}
# 定义分组范围（例如 0-1, 2-5, 6-10, 11-20, 21+）
bins = [0, 1, 2, 5, 10, 20, 50, 100, 200, 500, float('inf')]  # 更细化的分组区间
labels = ['1', '2', '3-5', '6-10', '11-20', '21-50', '51-100', '101-200', '201-500', '501+']  # 为每个区间指定标签

# 使用 pd.cut() 将数据分组
gdf['listings_range'] = pd.cut(gdf['host_listings_count'], bins=bins, labels=labels, right=True)

# 统计每个分组的数量和总数
range_counts = gdf['listings_range'].value_counts().sort_index()
total_hosts = range_counts.sum()

# 计算百分比
percentages = (range_counts / total_hosts) * 100

# 绘制柱状图
plt.figure(figsize=(8, 6))
ax = range_counts.plot(kind='bar', color='lightblue')

# 在柱状图上添加百分比标签
for i, (count, pct) in enumerate(zip(range_counts, percentages)):
    plt.text(i, count + 0.5, f'{pct:.1f}%', ha='center', va='bottom', fontsize=10)

# 添加标题和标签
plt.title('Number of Hosts by Listings Count Range')
plt.xlabel('Listings Count Range')
plt.ylabel('Number of Hosts')
plt.xticks(rotation=45)

# 显示图表
plt.show()
```

As shown in above picuture, nearly 40 thousand hosts own 1 listing. Two and three to five houses are owned by 10,000 landlords, respectively. And there are a small part of hosts owning dozens of even hundreds of listings (This could mean that theres the landlords are professional and manages multiple listings). 

Given that there are about a total of 85,000 listings, it can be inferred that more than half of the hosts **own multiple properties**. **多房非法性?**

```{python}
# 确保 'host_since' 是 datetime 格式
gdf['host_since'] = pd.to_datetime(gdf['host_since'])

# 提取年份信息
gdf['year'] = gdf['host_since'].dt.year

# --- 统计每年新增的 host_id 数量 ---
# 确保每个 host_id 只计算一次（每年新增）
new_hosts_per_year = gdf.drop_duplicates('host_id').groupby('year').size()

# --- 统计每年内的 id 数量（累积计算）---
# 创建一个年份范围（从最早到最新）
year_range = range(gdf['year'].min(), gdf['year'].max() + 1)

# 初始化每年运营中的 id 数量
id_per_year = [gdf[gdf['year'] <= year].shape[0] for year in year_range]

# 创建 DataFrame 并显示结果
result_df = pd.DataFrame({
    'Year': year_range,
    'New Hosts': new_hosts_per_year.reindex(year_range, fill_value=0),  # 填充缺失年份为0
    'Total IDs': id_per_year
})

# 绘制图形
fig, ax1 = plt.subplots(figsize=(12, 6))

# --- 绘制新增 host 数量（柱状图）---
ax1.bar(result_df['Year'], result_df['New Hosts'], color='blue', label='New Hosts per Year')
ax1.set_xlabel('Year')
ax1.set_ylabel('New Hosts', color='blue')
ax1.tick_params(axis='y', labelcolor='blue')

# --- 创建第二个 y 轴，绘制累计 id 数量（折线图）---
ax2 = ax1.twinx()
ax2.plot(result_df['Year'], result_df['Total IDs'], color='orange', marker='o', label='Total IDs')
ax2.set_ylabel('Listings count', color='orange')
ax2.tick_params(axis='y', labelcolor='orange')

# --- 添加图例 ---
fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))

# --- 设置标题 ---
plt.title('Yearly New Hosts and Listings on Airbnb in London')

# --- 显示图形 ---
plt.tight_layout()
plt.show()
```

```{python}
# 定义分组范围（例如 0-1, 2-5, 6-10, 11-20, 21+）
bins = [0, 1, 2, 5, 10, 20, 50, 100, 200, 500, float('inf')]  # 更细化的分组区间
labels = ['1', '2', '3-5', '6-10', '11-20', '21-50', '51-100', '101-200', '201-500', '501+']  # 为每个区间指定标签

# 使用 pd.cut() 将数据分组
gdf['listings_range'] = pd.cut(gdf['host_listings_count'], bins=bins, labels=labels, right=True)

# 统计每个分组的数量和总数
range_counts = gdf['listings_range'].value_counts().sort_index()
total_hosts = range_counts.sum()
percentages = (range_counts / total_hosts) * 100

# 确保 'host_since' 是 datetime 格式
gdf['host_since'] = pd.to_datetime(gdf['host_since'])
gdf['year'] = gdf['host_since'].dt.year

# 统计每年新增的 host_id 数量
new_hosts_per_year = gdf.drop_duplicates('host_id').groupby('year').size()

# 初始化每年运营中的 id 数量
year_range = range(gdf['year'].min(), gdf['year'].max() + 1)
id_per_year = [gdf[gdf['year'] <= year].shape[0] for year in year_range]

# 创建结果 DataFrame
result_df = pd.DataFrame({
    'Year': year_range,
    'New Hosts': new_hosts_per_year.reindex(year_range, fill_value=0),
    'Total IDs': id_per_year
})

# 创建一行两列的子图
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))  # 1行2列

# --- 第一个子图：每个分组的数量和百分比 ---

ax1.set_title('Number of Hosts by Listings Count Range')
ax1.set_xlabel('Listings Count Range')
ax1.set_ylabel('Number of Hosts')

range_counts.plot(kind='bar', color='lightblue', ax=ax1)
ax1.set_xticklabels(range_counts.index, rotation=45)

# 添加百分比标签
for i, (count, pct) in enumerate(zip(range_counts, percentages)):
    ax1.text(i, count + 0.5, f'{pct:.1f}%', ha='center', va='bottom', fontsize=10)

# --- 第二个子图：新增和累计 host 数量 ---
# 新增 hosts 柱状图
ax2.bar(result_df['Year'], result_df['New Hosts'], color='blue', label='New Hosts per Year')
ax2.set_xlabel('Year')
ax2.set_ylabel('New Hosts', color='blue')
ax2.tick_params(axis='y', labelcolor='blue')

# 累计 hosts 折线图
ax3 = ax2.twinx()  # 共享 x 轴的第二个 y 轴
ax3.plot(result_df['Year'], result_df['Total IDs'], color='orange', marker='o', label='Total Listings')
ax3.set_ylabel('Total Listings', color='orange')
ax3.tick_params(axis='y', labelcolor='orange')

# 添加图例
ax2.legend(loc='upper left')
ax3.legend(loc='upper right')

# --- 调整布局 ---
plt.tight_layout()
plt.show()
```

### 6.3 Analysis of property types

```{python}
#london['point_count'].sort_values()
#london.sort_values(by='point_count', ascending=True).head(50)
# london

# gdf.host_listings_count.sort_values()

gdf.info()
gdf.iloc[:,0:13]
# gdf.iloc[:,17:31]
```

```{python}
# unique = gdf.drop_duplicates(subset='host_id')
# unique.iloc[:,5:13]

# gdf[gdf['host_name'] == 'Blueground'].iloc[:,5:13]

# gdf[gdf['host_id'] == 314162972].iloc[:,5:13]
gdf[gdf['host_id'] == 439074505].iloc[:,5:13]
```

```{python}
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.patches as mpatches

# 创建主图框架，使用 subplot2grid
fig = plt.figure(figsize=(16, 8))  # 设置整个图的大小

# --- 第一个子图: 房源类型分布地图 ---
ax1 = plt.subplot2grid((4, 4), (0, 2), rowspan=4, colspan=2)  # 跨4行2列，显示在左侧

# 绘制背景地图
london.plot(ax=ax1, color='whitesmoke', edgecolor='black')

# 获取每个 room_type 的数量
room_counts = gdf['room_type'].value_counts()
total_count = len(gdf)  # 总房源数
# 获取唯一的 room_type 和颜色
room_types = gdf['room_type'].unique()
colors = plt.colormaps['viridis'](np.linspace(0, 1, len(room_types)))  # 生成颜色列表
# 绘制每个 room_type
for i, room_type in enumerate(room_types):
    subset = gdf[gdf['room_type'] == room_type]
    count = len(subset)
    percentage = (count / total_count) * 100  # 计算百分比
    subset.plot(ax=ax1, color=colors[i], marker='o', markersize=0.3, 
                label=f"{room_type} ({count}: {percentage:.1f}%)")  # 添加百分比

ax1.set_title('Airbnb Houses Categorized by Room Type', fontsize=15)
ax1.set_xlabel('Longitude')
ax1.set_ylabel('Latitude')
ax1.legend(title='Room Type', fontsize=10)

# --- 第二个子图: 按 property_type 绘制柱状图 ---
ax2 = plt.subplot2grid((4, 4), (0, 0), rowspan=4, colspan=2)  # 跨4行2列，显示在右侧

# 统计每种 property_type 的数量
property_counts = gdf['property_type'].value_counts()

# 筛选出数量超过 200 的类别
filtered_counts = property_counts[property_counts > 200]

# 绘制柱状图
filtered_counts.plot(kind='bar', color='skyblue', ax=ax2)

# 添加标题和标签
ax2.set_title('Number of Listings by Property Type (Count > 200)', fontsize=15)
ax2.set_xlabel('Property Type')
ax2.set_ylabel('Count')

# 旋转横轴标签，防止重叠
ax2.set_xticklabels(filtered_counts.index, rotation=45, ha='right')

# 调整布局并显示图表
plt.tight_layout()
plt.show()
```

* The high proportion of entire home listings indicates that Airbnb in London is becoming increasingly commercialized, with many properties likely dedicated specifically for rental purposes rather than occasional letting of spare space by hosts.

* As a major tourist destination, visitors to London tend to prefer entire homes to enjoy greater comfort and privacy, especially families or groups of travelers.

* The significant proportion of private rooms suggests that the Airbnb platform continues to cater to guests with different budgets and needs, particularly solo travelers or those who prefer interaction with hosts.

* The low numbers of shared rooms and hotel rooms may be related to local regulations and Airbnb's market positioning. For example, hotels may face regulatory restrictions, while shared rooms are less popular due to privacy concerns.

```{python}
# 创建并列的子图
fig, axes = plt.subplots(1, 2, figsize=(16, 6))  # 1行2列的子图

# 设置分箱：从 0 到 1000 每 25 一个分箱
bins = list(range(0, 1125, 25))

# 将超过 1000 的价格限制在 1000
price_clipped = np.where(gdf['price'] > 1000, 1000, gdf['price'])

# 计算直方图数据
counts, bin_edges, _ = axes[0].hist(price_clipped, bins=bins, color='skyblue', edgecolor='black')

# 设置标题和标签
axes[0].set_title('Distribution of Price (≤1000 per night, 1000+)', fontsize=15)
axes[0].set_xlabel('Price')
axes[0].set_ylabel('Count')

# 自定义 x 轴标签，每 100 显示一次，最后一个显示 1000+
x_labels = [str(i) for i in range(0, 1000, 100)] + ['1000+']
axes[0].set_xticks(range(0, 1100, 100))
axes[0].set_xticklabels(x_labels)

# 添加右侧 y 轴显示百分比
ax_right = axes[0].twinx()  # 创建双轴
ax_right.set_ylabel('Percentage')

# 计算百分比并设置右侧 y 轴刻度
total_counts = sum(counts)
percentages = (counts / total_counts) * 100
ax_right.set_ylim(0, max(percentages))  # 设置与左侧 y 轴对齐的百分比范围
ax_right.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.0f}%'))


# 将超过 35 天的值设置为 35 天
gdf['minimum_nights_clipped'] = np.where(gdf['minimum_nights'] > 35, 35, gdf['minimum_nights'])
bins = list(range(1, 37))  # 1 到 35 每天一个 bin，35+ 合并为一格

# 绘制 minimum_nights 列的直方图
axes[1].hist(gdf['minimum_nights_clipped'], bins=bins, color='lightblue', edgecolor='black')

# 添加阈值线 (在 30 天位置)
axes[1].axvline(x=30, color='black', linestyle='--', linewidth=1.5, label='STR Threshold (30 days)')

# 计算 30 天阈值之前的比例
threshold = 30
below_threshold = gdf[gdf['minimum_nights'] <= threshold].shape[0]  # 30天内的数量
total_entries = gdf.shape[0]  # 总数量
percentage_below = (below_threshold / total_entries) * 100

# 在图上显示百分比信息
axes[1].text(18, axes[1].get_ylim()[1] * 0.8,  # 设置位置
             f'{below_threshold} listings ({percentage_below:.1f}%) below 30 nights',
             fontsize=12, color='black', ha='center', bbox=dict(facecolor='white', alpha=0.6))

# 设置标题和标签
axes[1].set_title('Distribution of Minimum Nights', fontsize=15)
axes[1].set_xlabel('Minimum Nights')
axes[1].set_ylabel('Count')
axes[1].legend()

# 设置 x 轴刻度和标签
x_ticks = list(range(1, 8)) + list(range(10, 36, 5))  # 前7天每天显示, 10到35天每5天显示
x_labels = [str(i) for i in x_ticks[:-1]] + ['35+']  # 定义刻度标签
axes[1].set_xticks(x_ticks)
axes[1].set_xticklabels(x_labels)

# 显示图形
plt.tight_layout()
plt.show()
```

[@dignazio:2020], [@HofmannTess2020AiNY] 测试一下
[@McDonoughAnnie2019NYCf]
[@SeilerMichaelJ.2024AonA]

> ...

## 7. Drawing on your previous answers, and supporting your response with evidence (*e.g.* figures, maps, EDA/ESDA, and simple statistical analysis/models drawing on experience from, e.g., CASA0007), how *could* the InsideAirbnb data set be used to inform the regulation of Short-Term Lets (STL) in London? 

::: {.duedate}

( 45 points; Answer due {{< var assess.group-date >}} )

:::


## Sustainable Authorship Tools

Using the Terminal in Docker, you compile the Quarto report using `quarto render <group_submission_file>.qmd`.

Your QMD file should automatically download your BibTeX and CLS files and any other required files. If this is done right after library loading then the entire report should output successfully.

Written in Markdown and generated from [Quarto](https://quarto.org/). Fonts used: [Spectral](https://fonts.google.com/specimen/Spectral) (mainfont), [Roboto](https://fonts.google.com/specimen/Roboto) (<span style="font-family:Sans-Serif;">sansfont</span>) and [JetBrains Mono](https://fonts.google.com/specimen/JetBrains%20Mono) (`monofont`). 

## References
