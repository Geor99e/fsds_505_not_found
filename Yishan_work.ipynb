{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2f38baa-221d-47cc-b805-1a1a17c5c581",
   "metadata": {},
   "source": [
    "### Calculate the density of tourist attractions in each LSOA in London "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d3c04a9-2037-422f-9bb5-20b03c825844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: osmnx in /opt/conda/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: geopandas>=1.0 in /opt/conda/lib/python3.11/site-packages (from osmnx) (1.0.1)\n",
      "Requirement already satisfied: networkx>=2.5 in /opt/conda/lib/python3.11/site-packages (from osmnx) (3.3)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.11/site-packages (from osmnx) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.4 in /opt/conda/lib/python3.11/site-packages (from osmnx) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.27 in /opt/conda/lib/python3.11/site-packages (from osmnx) (2.32.3)\n",
      "Requirement already satisfied: shapely>=2.0 in /opt/conda/lib/python3.11/site-packages (from osmnx) (2.0.6)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /opt/conda/lib/python3.11/site-packages (from geopandas>=1.0->osmnx) (0.9.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from geopandas>=1.0->osmnx) (24.1)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/conda/lib/python3.11/site-packages (from geopandas>=1.0->osmnx) (3.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.4->osmnx) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.4->osmnx) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.4->osmnx) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.27->osmnx) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.27->osmnx) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.27->osmnx) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.27->osmnx) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade osmnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a1cf91c-df6f-46cd-8b13-2b08c36f96e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "print(ox.__version__)  # Should be 1.2.2 or newer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc9810e4-f2e7-4bf9-b3a5-36786b1a3678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tourist attraction density has been saved to data/london_lsoa_tourist_density.csv\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load London LSOA boundary data\n",
    "lsoa_boundaries = gpd.read_file(\"data/London/LSOA_2011_London_gen_MHW.shp\")\n",
    "\n",
    "# Step 2: Retrieve tourist attraction data for London\n",
    "# Use OSMnx to extract nodes tagged as `tourism=attraction`\n",
    "tourist_attractions = ox.features_from_place(\n",
    "    \"London, England\", tags={\"tourism\": \"attraction\"}\n",
    ")\n",
    "\n",
    "# Ensure the coordinate reference system (CRS) is consistent\n",
    "tourist_attractions = tourist_attractions.to_crs(lsoa_boundaries.crs)\n",
    "\n",
    "# Step 3: Count the number of tourist attractions within each LSOA\n",
    "lsoa_boundaries[\"tourist_attraction_count\"] = lsoa_boundaries.apply(\n",
    "    lambda row: tourist_attractions.within(row.geometry).sum(), axis=1\n",
    ")\n",
    "\n",
    "# Step 4: Calculate the density of tourist attractions (per square kilometer)\n",
    "# Transform to an equal-area projection to compute accurate area\n",
    "lsoa_boundaries = lsoa_boundaries.to_crs({\"proj\": \"cea\"})\n",
    "lsoa_boundaries[\"area_km2\"] = lsoa_boundaries.geometry.area / 1e6  # Convert to square kilometers\n",
    "\n",
    "# Tourist attraction density = count / area\n",
    "lsoa_boundaries[\"tourist_attraction_density\"] = (\n",
    "    lsoa_boundaries[\"tourist_attraction_count\"] / lsoa_boundaries[\"area_km2\"]\n",
    ")\n",
    "\n",
    "# Step 5: Export results to a CSV file\n",
    "# Use 'LSOA11CD' as the LSOA code column\n",
    "output_path = \"data/london_lsoa_tourist_density.csv\"\n",
    "output_csv = lsoa_boundaries[[\"LSOA11CD\", \"tourist_attraction_count\", \"tourist_attraction_density\"]]\n",
    "output_csv.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Tourist attraction density has been saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a00b27e-86bf-4854-aa5e-83770edce4ba",
   "metadata": {},
   "source": [
    "### Transfer rental price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b594de71-c1a5-4b5b-bd03-201e12be174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Postcode Avg asking rent (pm) Avg. household income\n",
      "666     BR1 1                1,501                67,100\n",
      "667     BR1 2                2,000                68,200\n",
      "668     BR1 3                1,650                62,800\n",
      "669     BR1 4                1,813                51,600\n",
      "670     BR1 5                  NaN                46,900\n",
      "...       ...                  ...                   ...\n",
      "7345    WV6 9                  NaN                45,600\n",
      "7346    WV7 3                  NaN                48,900\n",
      "7347    WV8 1                  NaN                40,200\n",
      "7348    WV8 2                  NaN                51,300\n",
      "7349    WV9 5                  NaN                39,300\n",
      "\n",
      "[2025 rows x 3 columns]\n",
      "筛选后的伦敦租金数据已保存！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 转换为UTF-8编码并保存\n",
    "with open(\"data/rental_price_postcode.csv\", \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "with open(\"data/rental_price_postcode.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(content)\n",
    "\n",
    "# 加载房租数据\n",
    "rental_data = pd.read_csv(\"data/rental_price_postcode.csv\")\n",
    "\n",
    "# 清洗数据：确保Postcode存在并无空值\n",
    "rental_data = rental_data.dropna(subset=['Postcode'])\n",
    "rental_data['Postcode'] = rental_data['Postcode'].astype(str).str.strip()\n",
    "\n",
    "# 定义伦敦的Postcode前缀\n",
    "london_postcodes = ['E', 'W', 'N', 'NW', 'SE', 'SW', 'EC', 'WC', 'BR', 'CR', 'DA', 'EN', 'HA', 'IG', 'KT', 'RM', 'SM', 'TW', 'UB', 'WD']\n",
    "\n",
    "# 筛选伦敦的Postcode\n",
    "rental_data['London'] = rental_data['Postcode'].str.startswith(tuple(london_postcodes))\n",
    "\n",
    "# 提取伦敦数据\n",
    "london_rentals = rental_data[rental_data['London']]\n",
    "\n",
    "# 筛选所需的列\n",
    "columns_to_keep = ['Postcode', 'Avg asking rent (pm)', 'Avg. household income']\n",
    "london_rentals_filtered = london_rentals[columns_to_keep]\n",
    "\n",
    "# 输出结果\n",
    "print(london_rentals_filtered)\n",
    "\n",
    "# 保存结果到新的CSV文件\n",
    "london_rentals_filtered.to_csv(\"data/london_rental_filtered.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"筛选后的伦敦租金数据已保存！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d7f23-c536-48de-af98-8e102e9b9d2d",
   "metadata": {},
   "source": [
    " ### Calculates hotel density for each LSOA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98397087-50a9-4f82-9f71-c09e9750517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_186/3352535683.py:12: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  lsoa_data['area_km2'] = lsoa_data['geometry'].area / 10**6\n",
      "/tmp/ipykernel_186/3352535683.py:15: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  london_boundary = lsoa_data.geometry.unary_union  # Merge all LSOA boundaries into a single polygon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotel density data saved to data/lsoa_hotel_density.csv\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# 1. Load LSOA boundary data\n",
    "lsoa_shp_path = \"data/London/LSOA_2011_London_gen_MHW.shp\"  \n",
    "lsoa_data = gpd.read_file(lsoa_shp_path)  # Load shapefile into GeoDataFrame\n",
    "lsoa_data = lsoa_data.to_crs(\"EPSG:4326\")  # Ensure the CRS is WGS84 for compatibility with OSM data\n",
    "\n",
    "# Calculate the area of each LSOA in square kilometers\n",
    "lsoa_data['area_km2'] = lsoa_data['geometry'].area / 10**6\n",
    "\n",
    "# 2. Get the London boundary\n",
    "london_boundary = lsoa_data.geometry.unary_union  # Merge all LSOA boundaries into a single polygon\n",
    "\n",
    "# 3. Fetch hotel data from OpenStreetMap\n",
    "# Use OSMnx's features_from_polygon method\n",
    "hotels = ox.features_from_polygon(london_boundary, tags={\"tourism\": \"hotel\"})\n",
    "\n",
    "# Convert the hotel data into a GeoDataFrame and retain only geometry\n",
    "hotels_gdf = gpd.GeoDataFrame(hotels[['geometry', 'name']].dropna(subset=['geometry']), crs=\"EPSG:4326\")\n",
    "\n",
    "# 4. Spatially join hotels to their respective LSOA units\n",
    "# Use GeoPandas's sjoin method\n",
    "hotels_in_lsoa = gpd.sjoin(hotels_gdf, lsoa_data, how=\"inner\", predicate=\"within\")\n",
    "\n",
    "# Count the number of hotels per LSOA\n",
    "hotel_counts = hotels_in_lsoa.groupby('LSOA11CD').size().reset_index(name='hotel_count')\n",
    "\n",
    "# 5. Calculate hotel density (number of hotels per square kilometer)\n",
    "# Merge hotel counts back into the LSOA data\n",
    "lsoa_data = lsoa_data.merge(hotel_counts, on='LSOA11CD', how='left')\n",
    "lsoa_data['hotel_count'] = lsoa_data['hotel_count'].fillna(0)  # Fill missing values with 0\n",
    "lsoa_data['hotel_density'] = lsoa_data['hotel_count'] / lsoa_data['area_km2']\n",
    "\n",
    "# 6. Save results to a CSV file\n",
    "output_csv_path = \"data/lsoa_hotel_density.csv\"  # Path for the output CSV file\n",
    "lsoa_data[['LSOA11CD', 'hotel_count', 'area_km2', 'hotel_density']].to_csv(output_csv_path, index=False)\n",
    "print(f\"Hotel density data saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6b002e-1a52-49fe-b63a-aa2a023e16cc",
   "metadata": {},
   "source": [
    "### Calculating five-year house price changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e32c4488-c8eb-405b-8491-9da4d17e703b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered London data has been saved to data/London_Housing_Data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path_xlsx = \"data/LSOA_Median_properties_price.xlsx\"\n",
    "\n",
    "# Load the data\n",
    "data_xlsx = pd.read_excel(file_path_xlsx, engine='openpyxl')\n",
    "\n",
    "# List of all London boroughs including the City of London\n",
    "london_boroughs = [\n",
    "    \"City of London\", \"Barking and Dagenham\", \"Barnet\", \"Bexley\", \"Brent\", \"Bromley\", \"Camden\",\n",
    "    \"Croydon\", \"Ealing\", \"Enfield\", \"Greenwich\", \"Hackney\", \"Hammersmith and Fulham\", \"Haringey\",\n",
    "    \"Harrow\", \"Havering\", \"Hillingdon\", \"Hounslow\", \"Islington\", \"Kensington and Chelsea\",\n",
    "    \"Kingston upon Thames\", \"Lambeth\", \"Lewisham\", \"Merton\", \"Newham\", \"Redbridge\",\n",
    "    \"Richmond upon Thames\", \"Southwark\", \"Sutton\", \"Tower Hamlets\", \"Waltham Forest\", \"Wandsworth\", \"Westminster\"\n",
    "]\n",
    "\n",
    "# Filter the data for London based on the local authority name\n",
    "london_data = data_xlsx[data_xlsx['Local authority name'].isin(london_boroughs)]\n",
    "\n",
    "# Save the filtered data to a CSV file\n",
    "output_csv_path = \"data/London_Housing_Data.csv\"\n",
    "london_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Filtered London data has been saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dcb6366-b420-4de7-9913-5e6908824fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Local authority code', 'Local authority name', 'LSOA code',\n",
      "       'LSOA name', 'Year ending Dec 1995', 'Year ending Mar 1996',\n",
      "       'Year ending Jun 1996', 'Year ending Sep 1996', 'Year ending Dec 1996',\n",
      "       'Year ending Mar 1997',\n",
      "       ...\n",
      "       'Year ending Dec 2020', 'Year ending Mar 2021', 'Year ending Jun 2021',\n",
      "       'Year ending Sep 2021', 'Year ending Dec 2021', 'Year ending Mar 2022',\n",
      "       'Year ending Jun 2022', 'Year ending Sep 2022', 'Year ending Dec 2022',\n",
      "       'Year ending Mar 2023'],\n",
      "      dtype='object', length=114)\n",
      "Missing values in Year columns:\n",
      "Year ending Mar 2023    386\n",
      "Year ending Dec 2018    359\n",
      "dtype: int64\n",
      "House price change data saved to 'LSOA_London_houseprice_change.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_186/705826425.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['Price_Change'] = (data_clean['Year ending Mar 2023'] - data_clean['Year ending Dec 2018']) / data_clean['Year ending Dec 2018'] * 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = pd.read_csv('data/London_Housing_Data.csv')\n",
    "\n",
    "# Step 2: Check the column names to ensure they are correct\n",
    "print(data.columns)  # This will print all column names\n",
    "\n",
    "# Strip any leading/trailing spaces in the column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Step 3: Convert 'Year ending Mar 2023' and 'Year ending Dec 2018' to numeric (if they are not already)\n",
    "data['Year ending Mar 2023'] = pd.to_numeric(data['Year ending Mar 2023'], errors='coerce')\n",
    "data['Year ending Dec 2018'] = pd.to_numeric(data['Year ending Dec 2018'], errors='coerce')\n",
    "\n",
    "# Check for missing values in the year columns after conversion\n",
    "missing_values = data[['Year ending Mar 2023', 'Year ending Dec 2018']].isnull().sum()\n",
    "print(f\"Missing values in Year columns:\\n{missing_values}\")\n",
    "\n",
    "# Optionally, drop rows with missing values for price calculations (only for the year columns)\n",
    "data_clean = data.dropna(subset=['Year ending Mar 2023', 'Year ending Dec 2018'])\n",
    "\n",
    "# Step 4: Calculate the price change rate between 'Year ending Mar 2023' and 'Year ending Dec 2018'\n",
    "data_clean['Price_Change'] = (data_clean['Year ending Mar 2023'] - data_clean['Year ending Dec 2018']) / data_clean['Year ending Dec 2018'] * 100\n",
    "\n",
    "# Step 5: Merge the price change back with the original data (using LSOA_code as the key)\n",
    "data_with_change = pd.merge(data, data_clean[['LSOA code', 'Price_Change']], on='LSOA code', how='left')\n",
    "\n",
    "# Step 6: Ensure data is sorted by LSOA code\n",
    "data_with_change_sorted = data_with_change.sort_values(by=['LSOA code'])\n",
    "\n",
    "# Step 7: Save the result to a new CSV file\n",
    "data_with_change_sorted[['LSOA code', 'Price_Change']].to_csv('data/LSOA_London_houseprice_change.csv', index=False)\n",
    "\n",
    "print(\"House price change data saved to 'LSOA_London_houseprice_change.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18095ba6-f6a8-4de3-92a1-19a055c7deef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted data/LSOA_IMD_london.xlsx to data/LSOA_IMD_london.csv\n",
      "Converted data/LSOA_population_density.xlsx to data/LSOA_population_density.csv\n"
     ]
    }
   ],
   "source": [
    "# Define paths for the input Excel files and output CSV files\n",
    "input_file_imd = \"data/LSOA_IMD_london.xlsx\"\n",
    "output_file_imd = \"data/LSOA_IMD_london.csv\"\n",
    "\n",
    "input_file_population = \"data/LSOA_population_density.xlsx\"\n",
    "output_file_population = \"data/LSOA_population_density.csv\"\n",
    "\n",
    "# Function to convert an Excel file to a CSV file\n",
    "def convert_excel_to_csv(input_path, output_path):\n",
    "    # Read the Excel file\n",
    "    data = pd.read_excel(input_path)\n",
    "    # Save the data to a CSV file\n",
    "    data.to_csv(output_path, index=False)\n",
    "    print(f\"Converted {input_path} to {output_path}\")\n",
    "\n",
    "# Convert LSOA_IMD_london.xlsx to LSOA_IMD_london.csv\n",
    "convert_excel_to_csv(input_file_imd, output_file_imd)\n",
    "\n",
    "# Convert LSOA_population_density.xlsx to LSOA_population_density.csv\n",
    "convert_excel_to_csv(input_file_population, output_file_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b90efd1-7e87-466c-af92-192c88b1adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df = pd.read_parquet(\"./20240614-London-listings.parquet\")  # 直接使用下载的 Parquet 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "588a465d-d5f6-4c99-9035-fdd5d505b102",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2045445874.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[55], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    jupyter server extension list\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51459068-9436-4658-93f2-4dc2f2693944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
